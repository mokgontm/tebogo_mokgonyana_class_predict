{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:28.471495Z",
     "iopub.status.busy": "2020-10-19T18:20:28.470445Z",
     "iopub.status.idle": "2020-10-19T18:20:28.477963Z",
     "shell.execute_reply": "2020-10-19T18:20:28.476630Z"
    },
    "papermill": {
     "duration": 0.038272,
     "end_time": "2020-10-19T18:20:28.478196",
     "exception": false,
     "start_time": "2020-10-19T18:20:28.439924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/climate-change-edsa2020-21/train.csv\n",
      "/kaggle/input/climate-change-edsa2020-21/test.csv\n",
      "/kaggle/input/climate-change-edsa2020-21/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022148,
     "end_time": "2020-10-19T18:20:28.527965",
     "exception": false,
     "start_time": "2020-10-19T18:20:28.505817",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021085,
     "end_time": "2020-10-19T18:20:28.572241",
     "exception": false,
     "start_time": "2020-10-19T18:20:28.551156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:28.626776Z",
     "iopub.status.busy": "2020-10-19T18:20:28.625922Z",
     "iopub.status.idle": "2020-10-19T18:20:31.069497Z",
     "shell.execute_reply": "2020-10-19T18:20:31.068781Z"
    },
    "papermill": {
     "duration": 2.475173,
     "end_time": "2020-10-19T18:20:31.069624",
     "exception": false,
     "start_time": "2020-10-19T18:20:28.594451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021253,
     "end_time": "2020-10-19T18:20:31.113623",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.092370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.170174Z",
     "iopub.status.busy": "2020-10-19T18:20:31.169278Z",
     "iopub.status.idle": "2020-10-19T18:20:31.284100Z",
     "shell.execute_reply": "2020-10-19T18:20:31.284735Z"
    },
    "papermill": {
     "duration": 0.149955,
     "end_time": "2020-10-19T18:20:31.284951",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.134996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')\n",
    "train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.352532Z",
     "iopub.status.busy": "2020-10-19T18:20:31.351697Z",
     "iopub.status.idle": "2020-10-19T18:20:31.364020Z",
     "shell.execute_reply": "2020-10-19T18:20:31.363121Z"
    },
    "papermill": {
     "duration": 0.057162,
     "end_time": "2020-10-19T18:20:31.364158",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.306996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.422233Z",
     "iopub.status.busy": "2020-10-19T18:20:31.421262Z",
     "iopub.status.idle": "2020-10-19T18:20:31.426945Z",
     "shell.execute_reply": "2020-10-19T18:20:31.426156Z"
    },
    "papermill": {
     "duration": 0.039633,
     "end_time": "2020-10-19T18:20:31.427077",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.387444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025542,
     "end_time": "2020-10-19T18:20:31.476962",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.451420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.534464Z",
     "iopub.status.busy": "2020-10-19T18:20:31.533552Z",
     "iopub.status.idle": "2020-10-19T18:20:31.536279Z",
     "shell.execute_reply": "2020-10-19T18:20:31.536932Z"
    },
    "papermill": {
     "duration": 0.035809,
     "end_time": "2020-10-19T18:20:31.537112",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.501303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y = train['sentiment']\n",
    "X = train['message']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "papermill": {
     "duration": 0.023883,
     "end_time": "2020-10-19T18:20:31.584999",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.561116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.649096Z",
     "iopub.status.busy": "2020-10-19T18:20:31.647557Z",
     "iopub.status.idle": "2020-10-19T18:20:31.653290Z",
     "shell.execute_reply": "2020-10-19T18:20:31.652333Z"
    },
    "papermill": {
     "duration": 0.044326,
     "end_time": "2020-10-19T18:20:31.653431",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.609105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def my_preprocessor(text):\n",
    "    \n",
    "      # split into words\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    import string\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "   \n",
    "    # filter out stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "       \n",
    "    # lemmatize\n",
    "    lemmatized_words = [stemmer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.711887Z",
     "iopub.status.busy": "2020-10-19T18:20:31.710951Z",
     "iopub.status.idle": "2020-10-19T18:20:31.715058Z",
     "shell.execute_reply": "2020-10-19T18:20:31.715780Z"
    },
    "papermill": {
     "duration": 0.036795,
     "end_time": "2020-10-19T18:20:31.715950",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.679155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    # create a space between special characters \n",
    "    text=re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n",
    "\n",
    "    # split based on whitespace\n",
    "    return re.split(\"\\\\s+\",text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024072,
     "end_time": "2020-10-19T18:20:31.764232",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.740160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vectorise the data so the model can undertands the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:31.825817Z",
     "iopub.status.busy": "2020-10-19T18:20:31.824614Z",
     "iopub.status.idle": "2020-10-19T18:20:49.361578Z",
     "shell.execute_reply": "2020-10-19T18:20:49.360903Z"
    },
    "papermill": {
     "duration": 17.573094,
     "end_time": "2020-10-19T18:20:49.361736",
     "exception": false,
     "start_time": "2020-10-19T18:20:31.788642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['', 'le', 'u'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# vectorise the data so the model can undertands\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter  = TfidfVectorizer(ngram_range=(1,2),tokenizer=my_tokenizer, min_df=2,max_df=0.80,analyzer='word',smooth_idf=False, preprocessor=my_preprocessor,stop_words=\"english\")\n",
    "X_vectorized    = tfidfconverter .fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:49.467067Z",
     "iopub.status.busy": "2020-10-19T18:20:49.456086Z",
     "iopub.status.idle": "2020-10-19T18:20:50.729408Z",
     "shell.execute_reply": "2020-10-19T18:20:50.728422Z"
    },
    "papermill": {
     "duration": 1.342799,
     "end_time": "2020-10-19T18:20:50.729575",
     "exception": false,
     "start_time": "2020-10-19T18:20:49.386776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       15819 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 123.7+ KB\n"
     ]
    }
   ],
   "source": [
    "count_vect_df = pd.DataFrame(X_vectorized)\n",
    "count_vect_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024322,
     "end_time": "2020-10-19T18:20:50.779244",
     "exception": false,
     "start_time": "2020-10-19T18:20:50.754922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split the data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:50.838378Z",
     "iopub.status.busy": "2020-10-19T18:20:50.837562Z",
     "iopub.status.idle": "2020-10-19T18:20:50.847921Z",
     "shell.execute_reply": "2020-10-19T18:20:50.847090Z"
    },
    "papermill": {
     "duration": 0.044107,
     "end_time": "2020-10-19T18:20:50.848049",
     "exception": false,
     "start_time": "2020-10-19T18:20:50.803942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split the data into Test and Train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_vectorized,y,test_size=0.20,shuffle=True, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:50.903928Z",
     "iopub.status.busy": "2020-10-19T18:20:50.902983Z",
     "iopub.status.idle": "2020-10-19T18:20:50.908148Z",
     "shell.execute_reply": "2020-10-19T18:20:50.907469Z"
    },
    "papermill": {
     "duration": 0.034828,
     "end_time": "2020-10-19T18:20:50.908277",
     "exception": false,
     "start_time": "2020-10-19T18:20:50.873449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-3338c251285d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-3338c251285d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Train the model\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:50.965830Z",
     "iopub.status.busy": "2020-10-19T18:20:50.964993Z",
     "iopub.status.idle": "2020-10-19T18:20:51.267590Z",
     "shell.execute_reply": "2020-10-19T18:20:51.266756Z"
    },
    "papermill": {
     "duration": 0.333728,
     "end_time": "2020-10-19T18:20:51.267748",
     "exception": false,
     "start_time": "2020-10-19T18:20:50.934020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train our machine learning model using the LinearSVC \n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:51.330533Z",
     "iopub.status.busy": "2020-10-19T18:20:51.329614Z",
     "iopub.status.idle": "2020-10-19T18:20:51.335201Z",
     "shell.execute_reply": "2020-10-19T18:20:51.334466Z"
    },
    "papermill": {
     "duration": 0.039478,
     "end_time": "2020-10-19T18:20:51.335351",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.295873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lsvc_pred = lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026135,
     "end_time": "2020-10-19T18:20:51.389598",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.363463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:51.450752Z",
     "iopub.status.busy": "2020-10-19T18:20:51.449971Z",
     "iopub.status.idle": "2020-10-19T18:20:51.456599Z",
     "shell.execute_reply": "2020-10-19T18:20:51.455944Z"
    },
    "papermill": {
     "duration": 0.038529,
     "end_time": "2020-10-19T18:20:51.456754",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.418225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get f1_score\n",
    "f1_score=f1_score(y_test, lsvc_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:51.516568Z",
     "iopub.status.busy": "2020-10-19T18:20:51.515809Z",
     "iopub.status.idle": "2020-10-19T18:20:51.519560Z",
     "shell.execute_reply": "2020-10-19T18:20:51.518971Z"
    },
    "papermill": {
     "duration": 0.035554,
     "end_time": "2020-10-19T18:20:51.519718",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.484164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538674206591586\n"
     ]
    }
   ],
   "source": [
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:51.581830Z",
     "iopub.status.busy": "2020-10-19T18:20:51.580707Z",
     "iopub.status.idle": "2020-10-19T18:20:51.596474Z",
     "shell.execute_reply": "2020-10-19T18:20:51.595642Z"
    },
    "papermill": {
     "duration": 0.049802,
     "end_time": "2020-10-19T18:20:51.596614",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.546812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.42      0.53       247\n",
      "           0       0.58      0.47      0.52       466\n",
      "           1       0.77      0.86      0.81      1749\n",
      "           2       0.76      0.74      0.75       702\n",
      "\n",
      "    accuracy                           0.74      3164\n",
      "   macro avg       0.71      0.62      0.65      3164\n",
      "weighted avg       0.74      0.74      0.73      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, lsvc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:20:51.660980Z",
     "iopub.status.busy": "2020-10-19T18:20:51.660168Z",
     "iopub.status.idle": "2020-10-19T18:21:00.887000Z",
     "shell.execute_reply": "2020-10-19T18:21:00.886311Z"
    },
    "papermill": {
     "duration": 9.261491,
     "end_time": "2020-10-19T18:21:00.887148",
     "exception": false,
     "start_time": "2020-10-19T18:20:51.625657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model with test data\n",
    "y_pred = lsvc.predict( tfidfconverter.transform(test['message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:21:00.956846Z",
     "iopub.status.busy": "2020-10-19T18:21:00.955652Z",
     "iopub.status.idle": "2020-10-19T18:21:00.960446Z",
     "shell.execute_reply": "2020-10-19T18:21:00.959845Z"
    },
    "papermill": {
     "duration": 0.045089,
     "end_time": "2020-10-19T18:21:00.960573",
     "exception": false,
     "start_time": "2020-10-19T18:21:00.915484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  sentiment\n",
       "0  Europe will now be looking to China to make su...   169760          1\n",
       "1  Combine this with the polling of staffers re c...    35326          1\n",
       "2  The scary, unimpeachable evidence that climate...   224985          1\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create sentiment from the predicts\n",
    "test['sentiment'] = y_pred\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030064,
     "end_time": "2020-10-19T18:21:01.019415",
     "exception": false,
     "start_time": "2020-10-19T18:21:00.989351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-19T18:21:01.085217Z",
     "iopub.status.busy": "2020-10-19T18:21:01.084332Z",
     "iopub.status.idle": "2020-10-19T18:21:01.410163Z",
     "shell.execute_reply": "2020-10-19T18:21:01.409360Z"
    },
    "papermill": {
     "duration": 0.361331,
     "end_time": "2020-10-19T18:21:01.410301",
     "exception": false,
     "start_time": "2020-10-19T18:21:01.048970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert output to csv\n",
    "test[['tweetid','sentiment']].to_csv('tebogo_mokgonyana_Log_regresssion_submission_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 38.755147,
   "end_time": "2020-10-19T18:21:01.547861",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-19T18:20:22.792714",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
